"""
data_pipeline/market/breadth.py
è² è²¬æŠ“å– S&P 500 å¸‚å ´å¯¬åº¦ -> å­˜æˆ data/breadth.csv
(æ¡ç”¨ Batch åˆ†æ‰¹é‹ç®—ï¼Œé˜²æ­¢è¨˜æ†¶é«”çˆ†ç‚¸)
"""
import yfinance as yf
import pandas as pd
import requests
from io import StringIO
import os
import gc  # åƒåœ¾å›æ”¶æ©Ÿåˆ¶ï¼Œç”¨ä¾†æ¸…è¨˜æ†¶é«”

def update():
    print("   â†³ ğŸ“Š [Breadth] æ­£åœ¨åˆ†æ S&P 500 å¸‚å ´å¯¬åº¦ (é˜²çˆ†æ¨¡å¼å•Ÿå‹•)...")
    
    START_DATE = "2007-01-01"
    BATCH_SIZE = 50  # æ¯æ¬¡åªè™•ç† 50 æª”è‚¡ç¥¨

    # 1. æŠ“æˆåˆ†è‚¡æ¸…å–®
    url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        r = requests.get(url, headers=headers)
        tickers = pd.read_html(StringIO(r.text))[0]['Symbol'].tolist()
        tickers = [t.replace('.', '-') for t in tickers]
    except Exception as e:
        print(f"   âŒ [Breadth] ç„¡æ³•æŠ“å–æˆåˆ†è‚¡: {e}")
        return

    # 2. ä¸‹è¼‰è³‡æ–™ (é€™æ­¥æœ€ä¹…ï¼Œè«‹è€å¿ƒç­‰å€™)
    print("      ğŸ“¥ ä¸‹è¼‰ 500 æª”è‚¡åƒ¹æ•¸æ“šä¸­...")
    try:
        data = yf.download(tickers, start=START_DATE, auto_adjust=True, threads=True, progress=False)['Close']
        # ç°¡å–®æ¸…ç†
        data = data.dropna(axis=1, how='all').ffill().astype('float32')
    except Exception as e:
        print(f"   âŒ [Breadth] ä¸‹è¼‰å¤±æ•—: {e}")
        return

    # 3. åˆ†æ‰¹è¨ˆç®—å¯¬åº¦ (ä½ çš„é˜²çˆ†é‚è¼¯)
    print("      ğŸ§® é–‹å§‹åˆ†æ‰¹é‹ç®— (Batch Processing)...")
    
    numerator_50 = pd.Series(0, index=data.index, dtype='float32')
    numerator_200 = pd.Series(0, index=data.index, dtype='float32')
    denominator = pd.Series(0, index=data.index, dtype='float32')

    all_cols = data.columns
    total_stocks = len(all_cols)

    # é–‹å§‹åˆ†æ‰¹åˆ‡è‚‰
    for i in range(0, total_stocks, BATCH_SIZE):
        batch_cols = all_cols[i : i + BATCH_SIZE]
        batch_data = data[batch_cols]
        
        # è¨ˆç®— MA
        ma50_batch = batch_data.rolling(window=50).mean()
        ma200_batch = batch_data.rolling(window=200).mean()
        
        # åˆ¤æ–·æ˜¯å¦ç«™ä¸Šå‡ç·š
        above_50_batch = (batch_data > ma50_batch).astype('float32')
        above_200_batch = (batch_data > ma200_batch).astype('float32')
        valid_batch = batch_data.notna().astype('float32')
        
        # ç´¯åŠ çµæœ
        numerator_50 = numerator_50.add(above_50_batch.sum(axis=1).fillna(0), fill_value=0)
        numerator_200 = numerator_200.add(above_200_batch.sum(axis=1).fillna(0), fill_value=0)
        denominator = denominator.add(valid_batch.sum(axis=1).fillna(0), fill_value=0)
        
        # ğŸ§¹ æ¸…ç†è¨˜æ†¶é«” (é—œéµï¼)
        del batch_data, ma50_batch, ma200_batch, above_50_batch, above_200_batch, valid_batch
        gc.collect()

    # è¨ˆç®—æœ€çµ‚ç™¾åˆ†æ¯”
    breadth_50 = (numerator_50 / denominator).fillna(0) * 100
    breadth_200 = (numerator_200 / denominator).fillna(0) * 100
    
    # å¹³æ»‘è™•ç† (é¿å…é‹¸é½’ç‹€å¤ªé†œ)
    breadth_50_smooth = breadth_50.rolling(window=3).mean()

    # æ¸…é™¤åŸå§‹å¤§æ•¸æ“šï¼Œé‡‹æ”¾è¨˜æ†¶é«”
    del data, numerator_50, numerator_200, denominator
    gc.collect()

    # 4. ä¸‹è¼‰å¤§ç›¤æŒ‡æ•¸ (ç•¶ä½œåŸºæº–)
    print("      ğŸ“¥ ä¸‹è¼‰ S&P 500 æŒ‡æ•¸...")
    sp500_df = yf.download("^GSPC", start=START_DATE, auto_adjust=True, progress=False)
    sp500 = sp500_df['Close'].squeeze() if 'Close' in sp500_df.columns else sp500_df.squeeze()

    # 5. åˆä½µä¸¦å­˜æª”
    df_result = pd.DataFrame({
        "value": sp500,
        "breadth_200": breadth_200,
        "breadth_50": breadth_50_smooth
    }).dropna().reset_index()

    # çµ±ä¸€æ¬„ä½åç¨±
    if "Date" in df_result.columns:
        df_result.rename(columns={"Date": "date"}, inplace=True)
    
    # å­˜æª”
    if not os.path.exists("data"): os.makedirs("data")
    file_path = "data/breadth.csv"
    df_result.to_csv(file_path, index=False)
    
    print(f"   âœ… [Breadth] æˆåŠŸæ›´æ–°ä¸¦å­˜æª”: {file_path}")

if __name__ == "__main__":
    update()