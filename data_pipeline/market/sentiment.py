"""
data_pipeline/market/sentiment.py
è² è²¬æŠ“å– AAII æ•£æˆ¶æƒ…ç·’èˆ‡ S&P 500 å°ç…§æ•¸æ“š (åŒ…å«è¶…å¼· Excel æ™ºæ…§è§£æ)
"""
import pandas as pd
import requests
import yfinance as yf
import os
import io
# è¨­å®šè³‡æ–™è·¯å¾‘
DATA_DIR = "data"
SENTIMENT_FILE = os.path.join(DATA_DIR, "sentiment.csv")
HISTORY_FILE = os.path.join(DATA_DIR, "AAII_History.xlsx") 

def get_aaii_latest():
    """å¾ AAII å®˜ç¶²æŠ“å–æœ€æ–°ä¸€é€±æ•¸æ“š"""
    url = "https://www.aaii.com/sentimentsurvey/sent_results"
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8",
        "Accept-Language": "en-US,en;q=0.5",
        "Accept-Encoding": "gzip, deflate, br",
        "Connection": "keep-alive",
        "Upgrade-Insecure-Requests": "1",
        "Sec-Fetch-Dest": "document",
        "Sec-Fetch-Mode": "navigate",
        "Sec-Fetch-Site": "none",
        "Sec-Fetch-User": "?1",
        "Cache-Control": "max-age=0",
    }
    
    try:
        r = requests.get(url, headers=headers)
        # è§£æ±º html5lib çš„é»ƒè‰²è­¦å‘Š
        import io
        tables = pd.read_html(io.StringIO(r.text), flavor='html5lib')
        df = tables[0].iloc[:, [0, 1, 2, 3]]
        df.columns = ['Date', 'Bullish', 'Neutral', 'Bearish']
        
        # ğŸ”¥ ä¿®æ­£ 1ï¼šå¼·åˆ¶è½‰æ›æ—¥æœŸï¼Œè‹¥é‡åˆ° 'Reported Date' é€™ç¨®æ–‡å­—æœƒè®Š NaTï¼Œç„¶å¾ŒæŠŠå®ƒåˆªæ‰
        df['Date'] = pd.to_datetime(df['Date'], errors='coerce', format='mixed')
        df = df.dropna(subset=['Date'])
        
        for col in ['Bullish', 'Neutral', 'Bearish']:
            if df[col].dtype == object:
                df[col] = df[col].astype(str).str.replace('%', '').astype(float)
        
        df['Spread'] = df['Bullish'] - df['Bearish']
        return df
        
    except Exception as e:
        print(f"      [Error] AAII çˆ¬èŸ²å¤±æ•—: {e}")
        return pd.DataFrame()

def update():
    """ä¸»æ›´æ–°å‡½æ•¸ï¼šæ•´åˆæ­·å²æª” + ç¶²è·¯çˆ¬èŸ² + S&P 500"""
    print("   â†³ ğŸ‚ğŸ» [AAII Sentiment] æ­£åœ¨æ›´æ–°æ•£æˆ¶æƒ…ç·’æŒ‡æ¨™...")
    
    if os.path.exists(SENTIMENT_FILE):
        base_df = pd.read_csv(SENTIMENT_FILE, parse_dates=['Date'])
    elif os.path.exists(HISTORY_FILE):
        # ğŸ’¡ [æ™ºæ…§è§£æ] å®¹å¿å„ç¨® Excel æ ¼å¼
        try:
            # è®€å–ä½ çš„ Excel æª”
            base_df = pd.read_excel(HISTORY_FILE, engine='openpyxl')
            
            # è™•ç† Date æ¬„ä½åç¨± (å¦‚æœå®˜æ–¹è¡¨é ­å« Reported Dateï¼Œè‡ªå‹•æ”¹å)
            if 'Reported Date' in base_df.columns:
                base_df = base_df.rename(columns={'Reported Date': 'Date'})
                
            base_df['Date'] = pd.to_datetime(base_df['Date'], errors='coerce')
            base_df = base_df.dropna(subset=['Date']) # åˆªé™¤æ²’æœ‰æ—¥æœŸçš„ç„¡æ•ˆè¡Œ
            
            # ğŸ”¥ æ ¸å¿ƒé­”æ³•ï¼šè‡ªå‹•æŠŠ 0.75 é€™ç¨®å°æ•¸è½‰æ›æˆ 75.0
            for col in ['Bullish', 'Neutral', 'Bearish']:
                if col in base_df.columns:
                    # å¼·åˆ¶è½‰ç‚ºæ•¸å­—ï¼Œå¿½ç•¥ç„¡æ³•è½‰æ›çš„æ–‡å­—
                    base_df[col] = pd.to_numeric(base_df[col], errors='coerce')
                    # å¦‚æœé€™æ¬„çš„æœ€å¤§å€¼å°æ–¼æˆ–ç­‰æ–¼ 1.5ï¼Œä»£è¡¨å®ƒæ˜¯ç™¾åˆ†æ¯”å°æ•¸ (ä¾‹å¦‚ 0.75)
                    if base_df[col].max() <= 1.5:
                        base_df[col] = base_df[col] * 100
                        
            if 'Spread' not in base_df.columns and 'Bullish' in base_df.columns:
                base_df['Spread'] = base_df['Bullish'] - base_df['Bearish']
                
            # åªå–æˆ‘å€‘è¦çš„æ¬„ä½
            base_df = base_df[['Date', 'Bullish', 'Neutral', 'Bearish', 'Spread']]
            
        except Exception as e:
            print(f"      [Error] è®€å– Excel å¤±æ•—: {e}")
            base_df = pd.DataFrame(columns=['Date', 'Bullish', 'Neutral', 'Bearish', 'Spread'])
    else:
        print("      âš ï¸ è­¦å‘Šï¼šæ‰¾ä¸åˆ° sentiment.csv æˆ– AAII_History.xlsxï¼Œå°‡åˆå§‹åŒ–ç©ºè¡¨")
        base_df = pd.DataFrame(columns=['Date', 'Bullish', 'Neutral', 'Bearish', 'Spread'])

    # 2. æŠ“å–æœ€æ–°æ•¸æ“šä¸¦åˆä½µ
    new_df = get_aaii_latest()
    if not new_df.empty:
        cols = ['Date', 'Bullish', 'Neutral', 'Bearish', 'Spread']
        base_df = base_df[cols] if not base_df.empty else base_df
        new_df = new_df[cols]
        full_df = pd.concat([base_df, new_df]).drop_duplicates(subset=['Date'], keep='last').sort_values('Date')
    else:
        full_df = base_df

    if full_df.empty:
        return

    # 3. é‡ç®— 20 é€±å‡ç·š
    full_df['Spread_MA20'] = full_df['Spread'].rolling(window=20).mean()

    # 4. è£œä¸Š S&P 500 æ”¶ç›¤åƒ¹
# 4. è£œä¸Š S&P 500 æ”¶ç›¤åƒ¹
    start_date = full_df['Date'].min()
    try:
        sp500 = yf.download("^GSPC", start=start_date, progress=False, auto_adjust=False)['Close']
        if not sp500.empty:
            if isinstance(sp500, pd.DataFrame):
                sp500 = sp500.iloc[:, 0]
            sp500 = sp500.reset_index()
            sp500.columns = ['Date', 'SP500_Price']
            
            # ğŸ”¥ ä¿®æ­£ 2ï¼šåˆä½µå‰å…ˆåˆªé™¤èˆŠæœ‰çš„ SP500_Priceï¼Œé¿å…æ¬„ä½åç¨±è¡çª (_x, _y)
            if 'SP500_Price' in full_df.columns:
                full_df = full_df.drop(columns=['SP500_Price'])
                
            full_df = pd.merge_asof(full_df.sort_values('Date'), 
                                    sp500.sort_values('Date'), 
                                    on='Date', 
                                    direction='backward')
    except Exception as e:
        print(f"      [Error] S&P 500 ä¸‹è¼‰å¤±æ•—: {e}")
    # 5. å­˜æª”
    if not os.path.exists(DATA_DIR):
        os.makedirs(DATA_DIR)
    full_df.to_csv(SENTIMENT_FILE, index=False)
    print(f"   âœ… [AAII Sentiment] å„²å­˜æˆåŠŸï¼Œæœ€æ–°æ—¥æœŸ: {full_df['Date'].iloc[-1].strftime('%Y-%m-%d')}")